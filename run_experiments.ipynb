{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce47b097-f23c-4e1d-9c17-7636fe7659c3",
   "metadata": {},
   "source": [
    "# Experiments Multiview Stacking TDA MNIST\n",
    "\n",
    "## Introduction\n",
    "This notebook explores the hypothesis that a **multi-view model** incorporating **topological features** (TDA) outperforms models that do **not** include these features. Specifically, we adopt a technique called **Multiview Stacking**, where multiple “views” of the same dataset (e.g., different image quadrants, topological features, or full original images) are combined via a stacking ensemble to improve classification performance.\n",
    "\n",
    "### Motivation\n",
    "1. **Topological Data Analysis (TDA)** aims to capture intrinsic shape information from data, hypothesized to be complementary to the raw pixel view.\n",
    "2. **Multiview Stacking** merges multiple feature sets—e.g. original image pixels, TDA features, and image quadrants—so each “view” acts like a separate input stream. A meta-learner (here, a RandomForest) then learns from these base learners.\n",
    "\n",
    "### Hypothesis\n",
    "> *“Including topological features (via TDA) in a multi-view stacking ensemble yields higher predictive performance than a model without TDA.”*\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Dataset and Chunk Processing**  \n",
    "   - We load MNIST data from `mnist_784.csv` in **chunks** to manage memory usage and to run multiple iterations (`NUMBER_EXPERIMENTS`). Each chunk is split into training and test sets.\n",
    "   - We optionally reshape images to a square (28×28) for quadrant splitting and TDA extraction.\n",
    "\n",
    "2. **View Creation**  \n",
    "   - **Original**: Flattened image (784 features).  \n",
    "   - **TDA**: Topological features extracted with a pipeline built via `build_tda_pipeline`.  \n",
    "   - **Quadrants**: Four 14×14 image subsections (`top_left`, `top_right`, `bottom_left`, `bottom_right`).  \n",
    "\n",
    "3. **Ablation / View Combinations**  \n",
    "   - We generate all possible subsets of the full set of views: `[\"original\", \"tda\", \"top_left\", \"top_right\", \"bottom_left\", \"bottom_right\"]`. \n",
    "   - For each subset (e.g., `\"original+tda\"`, `\"top_left+tda\"`, …), we:\n",
    "     1. Concatenate or keep separate features in a dictionary.  \n",
    "     2. Train a **multi-view stacking** model (via `train_multiview_stacking`) with a RandomForest meta-learner.  \n",
    "     3. Evaluate classification performance.\n",
    "\n",
    "4. **Data Flow and Iterations**  \n",
    "   - Each chunk processes all view combinations, then we move to the next chunk. We limit the total to `NUMBER_EXPERIMENTS`.\n",
    "   - For each chunk and combination, the code logs performance (`classification_report`) and predictions in a global `results` dictionary.\n",
    "\n",
    "5. **Main Experiment Steps**  \n",
    "   1. **Initialize**: Logging, random seeds, create experiment directory.  \n",
    "   2. **Load Data in Chunks**: `read_csv_in_chunks(file_path, CHUNK_SIZE)`  \n",
    "   3. **Train/Test Split**: A portion is used for training, the rest for validation.  \n",
    "   4. **Generate Quadrants + TDA**: `split_image_into_quadrants` and `tda_pipeline`.  \n",
    "   5. **Loop Over Combinations**: `generate_view_combinations(VIEWS)` enumerates all subsets.  \n",
    "   6. **Train and Collect**: Call `train_multiview_stacking(...)`, store `report`, `y_pred`, `y_true`.  \n",
    "   7. **Repeat** for each chunk until `NUMBER_EXPERIMENTS` is reached.  \n",
    "   8. **Save and Summarize**: The function `finalize_and_save_results` writes out CSV files with metrics and predictions.  \n",
    "\n",
    "## Using the Main Experiment Function\n",
    "\n",
    "The entry point is `main_experiment()`. It:\n",
    "1. Creates logs and an experiment directory for saving outputs.  \n",
    "2. Loads data, chunk by chunk, from **MNIST** (`mnist_784.csv`).  \n",
    "3. Generates a TDA pipeline and quadrant data for each chunk.  \n",
    "4. Iterates over each **view combination** to train and evaluate multi-view stacking.  \n",
    "5. Collects performance metrics and predictions in a `results` dictionary.  \n",
    "6. Writes comprehensive metrics (precision, recall, F1-score, support) to CSV, plus predictions and ground truths for further analysis.\n",
    "\n",
    "### Configurations\n",
    "Inside the function, you can modify:\n",
    "- `RF_N_ESTIMATORS`: Number of trees in the RandomForest meta-learner.  \n",
    "- `RANDOM_STATE`: Seed for reproducibility.  \n",
    "- `NUMBER_EXPERIMENTS`: How many chunks to process.  \n",
    "- `CHUNK_SIZE`: How large each data chunk is.  \n",
    "- `VIEWS`: The set of potential feature subsets.  \n",
    "- `N_JOBS`: Number of parallel jobs for the RandomForest and TDA pipeline.\n",
    "\n",
    "### Expected Results\n",
    "- A CSV of **detailed metrics** for each combination (e.g., accuracy, macro-F1, per-class metrics).  \n",
    "- (Optionally) A file of **predictions** and **ground truths** for deeper error analysis.  \n",
    "- Higher performance for view combinations that include TDA features, if our hypothesis holds true.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- You need to have installed multiviewstacking: `pip install multiviewstacking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4709a72-62d2-48b6-88b8-2fb6a31e7ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Standard Library Imports\n",
    "# ============================\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from dataclasses import asdict\n",
    "from dataclasses import fields\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Third-Party Library Imports\n",
    "# ============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# Local Application Imports\n",
    "# ============================\n",
    "from experiment.Experiment import Experiment\n",
    "from experiment.ExperimentConfig import ExperimentConfig\n",
    "\n",
    "\n",
    "def save_configs_to_json(\n",
    "    configs: list[ExperimentConfig],\n",
    "    path: Path\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves a list of ExperimentConfig instances to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        configs (List[ExperimentConfig]): List of configs to save.\n",
    "        path (Path): Path to the JSON file.\n",
    "    \"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(\n",
    "            [asdict(cfg) for cfg in configs],\n",
    "            f,\n",
    "            indent=4,\n",
    "            default=str  # Needed to serialize Path objects\n",
    "        )\n",
    "\n",
    "\n",
    "def load_configs_from_json(path: Path) -> list[ExperimentConfig]:\n",
    "    \"\"\"\n",
    "    Loads a list of ExperimentConfig instances from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        List[ExperimentConfig]: List of experiment configurations.\n",
    "    \"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    config_fields = {field.name for field in fields(ExperimentConfig)}\n",
    "\n",
    "    configs = []\n",
    "    for item in data:\n",
    "        # Filter only valid fields (in case JSON has extra stuff)\n",
    "        clean_item = {k: v for k, v in item.items() if k in config_fields}\n",
    "        configs.append(ExperimentConfig(**clean_item))\n",
    "\n",
    "    return configs\n",
    "\n",
    "\n",
    "def run_experiments_from_saved_configs(config_file: Path) -> None:\n",
    "    \"\"\"\n",
    "    Runs experiments loaded from a previously saved configuration file.\n",
    "\n",
    "    Args:\n",
    "        config_file (Path): Path to the JSON file containing configs.\n",
    "    \"\"\"\n",
    "    configs = load_configs_from_json(config_file)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for config in tqdm(configs, desc=\"Running Loaded Experiments\"):\n",
    "        run_experiment(config)\n",
    "\n",
    "    elapsed_time = (time.perf_counter() - start_time) / 60\n",
    "    print(f\"✅ Experiments complete! Time: {elapsed_time:.2f} minutes\")\n",
    "\n",
    "\n",
    "def generate_experiment_configs(\n",
    "    num_runs: int,\n",
    "    seed: int,\n",
    "    exp_name: str,\n",
    "    train_splits: list[float],\n",
    "    noise_types: list[str],\n",
    "    noise_quantities: list[int],\n",
    "    noise_transparencies: Optional[list[float]] = None,\n",
    ") -> list[ExperimentConfig]:\n",
    "    \"\"\"\n",
    "    Generates a list of experiment configurations \n",
    "    varying train splits, noise types, noise quantities, \n",
    "    and optional noise transparencies.\n",
    "    \"\"\"\n",
    "    random.seed(int(seed))\n",
    "    random_states = random.sample(range(10**5, 10**9), num_runs)\n",
    "\n",
    "    if noise_transparencies is None:\n",
    "        noise_transparencies = [1.0]  # Default to full opacity if not set\n",
    "\n",
    "    vary_train_split = len(train_splits) > 1\n",
    "\n",
    "    configs = []\n",
    "    for rs in random_states:\n",
    "        for (\n",
    "            train_split,\n",
    "            noise_type,\n",
    "            noise_quantity,\n",
    "            noise_transparency\n",
    "        ) in product(\n",
    "            train_splits,\n",
    "            noise_types,\n",
    "            noise_quantities,\n",
    "            noise_transparencies\n",
    "        ):\n",
    "            config = ExperimentConfig(\n",
    "                exp_name=exp_name,\n",
    "                results_dir=Path(f\"results/{exp_name}\"),\n",
    "                log_dir=Path(f\"logs/{exp_name}\"),\n",
    "                random_state=rs,\n",
    "                train_split=train_split,\n",
    "                vary_train_split=vary_train_split,\n",
    "                noise_enabled=True if noise_type else False,\n",
    "                noise_type=noise_type,\n",
    "                noise_quantity=noise_quantity,\n",
    "                noise_transparency=noise_transparency\n",
    "            )\n",
    "            configs.append(config)\n",
    "\n",
    "    return configs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(config: ExperimentConfig) -> None:\n",
    "    \"\"\"\n",
    "    Runs a single experiment given an ExperimentConfig.\n",
    "    \"\"\"\n",
    "    exp = Experiment(config)\n",
    "    exp.run_experiment()\n",
    "\n",
    "\n",
    "def run_multiple_experiments(\n",
    "    num_runs: int,\n",
    "    exp_name: str,\n",
    "    train_splits: list[float],\n",
    "    noise_types: list[str],\n",
    "    noise_quantities: list[int],\n",
    "    noise_transparencies: Optional[list[float]] = None,\n",
    "    seed: int = 56) -> None:\n",
    "    \"\"\"\n",
    "    Runs multiple experiments with varying configurations.\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    \n",
    "    configs = generate_experiment_configs(\n",
    "        num_runs=num_runs,\n",
    "        seed=seed,\n",
    "        exp_name=exp_name,\n",
    "        train_splits=train_splits,\n",
    "        noise_types=noise_types,\n",
    "        noise_quantities=noise_quantities,\n",
    "        noise_transparencies=noise_transparencies,\n",
    "    )\n",
    "\n",
    "    # Save configs before running\n",
    "    save_configs_to_json(\n",
    "        configs,\n",
    "        path=Path(f\"experiments_configs/{exp_name}_configs.json\")\n",
    "    )\n",
    "\n",
    "    for config in tqdm(configs, desc=\"Running Experiments\"):\n",
    "        run_experiment(config)\n",
    "\n",
    "    \n",
    "    def format_elapsed_time(seconds: float) -> str:\n",
    "        \"\"\"Formats time for better readability.\"\"\"\n",
    "        minutes = seconds / 60\n",
    "        if minutes < 60:\n",
    "            return f\"{minutes:.2f} minutes\"\n",
    "        hours = minutes / 60\n",
    "        return f\"{hours:.2f} hours\"\n",
    "\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    print(f\"✅ Experiments complete! Total time elapsed: {format_elapsed_time(elapsed_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ccef0-bdb0-429a-9b2c-7a85fd98a68c",
   "metadata": {},
   "source": [
    "# Run HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5c654-7f87-44ad-9713-efbc35cc538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FROM_SAVED_CONFIG = False\n",
    "CONFIG_PATH = \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if RUN_FROM_SAVED_CONFIG:\n",
    "        if not CONFIG_PATH:\n",
    "            raise ValueError(\n",
    "                \"CONFIG_PATH must be set if RUN_FROM_SAVED_CONFIG is True.\"\n",
    "            )\n",
    "        print(f\"Running experiments from saved configs at {CONFIG_PATH}\")\n",
    "        run_experiments_from_saved_configs(Path(CONFIG_PATH))\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"Generating and running new experiment configurations.\")\n",
    "        run_multiple_experiments(\n",
    "            num_runs=1,\n",
    "            exp_name=\"test\",\n",
    "            train_splits=[0.9],\n",
    "            noise_types=[\"\"],\n",
    "            noise_quantities=[0],\n",
    "            noise_transparencies=[0],\n",
    "            seed=44712\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe9d6d-7d70-4838-a99a-1528143a5d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
